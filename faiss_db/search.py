import faiss
import os
import numpy as np
import sqlite3
from langchain_community.embeddings import OpenAIEmbeddings  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
import os
import time
import json
from config import OPENAI_API_KEY

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
FAISS_INDEX_PATH = "./faiss_index"
SQLITE_DB_PATH = "./faiss_index/metadata.db"
OPENAI_API_KEY =  OPENAI_API_KEY
DIMENSION = 1536
TOP_K = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=OPENAI_API_KEY)


def convert_to_serializable(data):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ JSON."""
    if isinstance(data, dict):
        return {key: convert_to_serializable(value) for key, value in data.items()}
    elif isinstance(data, list):
        return [convert_to_serializable(item) for item in data]
    elif isinstance(data, (np.int64, np.int32)):
        return int(data)
    elif isinstance(data, (np.float64, np.float32)):
        return float(data)
    else:
        return data


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è –∏–Ω–¥–µ–∫—Å–æ–≤ FAISS
faiss_indices = None  

def load_indices():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã FAISS –≤ –ø–∞–º—è—Ç—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ."""
    global faiss_indices
    if faiss_indices is None:
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å—ã –≤ –ø–∞–º—è—Ç—å...")
        faiss_indices = {
            "title": faiss.read_index(os.path.join(FAISS_INDEX_PATH, "title_index.faiss")),
            "cause": faiss.read_index(os.path.join(FAISS_INDEX_PATH, "cause_index.faiss")),
            "solution": faiss.read_index(os.path.join(FAISS_INDEX_PATH, "solution_index.faiss")),
        }
    return faiss_indices


def embed_query(query):
    """–°–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
    query_vector = np.array(embeddings.embed_query(query)).astype(np.float32).reshape(1, -1)
    return query_vector


def search_index(index, query_vector, top_k=TOP_K):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –∏–Ω–¥–µ–∫—Å—É FAISS –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–ª–∏–∂–∞–π—à–∏–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è."""
    distances, ids = index.search(query_vector, top_k)
    return ids[0], distances[0]


def get_metadata(ids, distances):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–¥–∞–Ω–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤, —Å–æ—Ä—Ç–∏—Ä—É—è –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º."""
    results = []
    conn = sqlite3.connect(SQLITE_DB_PATH)
    cursor = conn.cursor()

    for id_, distance in sorted(zip(ids, distances), key=lambda x: x[1]):
        if id_ == -1:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
            continue
        id_ = int(id_) + 1
        cursor.execute("""
            SELECT idea_number, status, title, cause, solution 
            FROM metadata 
            WHERE id = ?
        """, (id_,))
        row = cursor.fetchone()
        if row:
            results.append({
                "distance": distance,
                "–Ω–æ–º–µ—Ä –∏–¥–µ–∏": row[0],
                "—Å—Ç–∞—Ç—É—Å": row[1],
                "–Ω–∞–∑–≤–∞–Ω–∏–µ": row[2],
                "–æ–ø–∏—Å–∞–Ω–∏–µ": row[3],
                "—Ä–µ—à–µ–Ω–∏–µ": row[4]
            })

    conn.close()
    return results


def remove_duplicates(metadata):
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
    unique_combinations = set()
    unique_results = []

    for record in metadata:
        combination = (record["title"], record["cause"], record["solution"])
        if combination not in unique_combinations:
            unique_combinations.add(combination)
            unique_results.append(record)

    return unique_results


def search_problem(query):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON-—Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    indices = load_indices()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
    query_vector = embed_query(query)

    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –∏–Ω–¥–µ–∫—Å–∞–º
    title_ids, title_distances = search_index(indices["title"], query_vector)
    cause_ids, cause_distances = search_index(indices["cause"], query_vector)
    solution_ids, solution_distances = search_index(indices["solution"], query_vector)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    title_metadata = get_metadata(title_ids, title_distances)
    cause_metadata = get_metadata(cause_ids, cause_distances)
    solution_metadata = get_metadata(solution_ids, solution_distances)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–ª—è–º
    seen = set()
    unique_metadata = []
    for record in title_metadata + cause_metadata + solution_metadata:
        record_tuple = (record["–Ω–∞–∑–≤–∞–Ω–∏–µ"], record["–æ–ø–∏—Å–∞–Ω–∏–µ"], record["—Ä–µ—à–µ–Ω–∏–µ"])
        if record_tuple not in seen:
            seen.add(record_tuple)
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è distance –∏–∑ float32 –≤ float
            record["distance"] = float(record["distance"])
            unique_metadata.append(record)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
    sorted_metadata = sorted(unique_metadata, key=lambda x: x["distance"])

    return json.dumps({"–ø—Ä–æ–±–ª–µ–º—ã": sorted_metadata}, ensure_ascii=False, indent=4)

if __name__ == "__main__":
    query = input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: ")
    result_json = search_problem(query)
    print(result_json)
